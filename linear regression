## Importing the libraries/packeges

import matplotlib.pyplot as plt
import pandas as pd
import pylab as pl
import numpy as np
%matplotlib inline


## Downloading data
!wget -O FuelConsumption.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/FuelConsumptionCo2.csv

## Reading the data
df = pd.read_csv("FuelConsumption.csv")

## take a look at the dataset
df.head()


## summarize the data
df.describe()

## Read some information from dataset
cdf = df[['ENGINESIZE','CYLINDERS','FUELCONSUMPTION_COMB','CO2EMISSIONS']]
cdf.head(9)

## Compute historgram of these quantities
viz = cdf[['CYLINDERS','ENGINESIZE','CO2EMISSIONS','FUELCONSUMPTION_COMB']]
viz.hist() ## Computation of the histogram
plt.show() ## will re-draw the figure. This allows you to work in interactive mode and, should you have changed your data or formatting, allow the graph itself to change.


## Plot the relation between fuelconsumption vs co2 emission

plt.scatter(cdf.FUELCONSUMPTION_COMB, cdf.CO2EMISSIONS,  color='blue') ## Plot as scatter
plt.xlabel("FUELCONSUMPTION_COMB") ## X_label
plt.ylabel("Emission") ## y_label
plt.show()

## Plot the relation between enginesize vs co2 emission

plt.scatter(cdf.ENGINESIZE, cdf.CO2EMISSIONS,  color='blue')
plt.xlabel("Engine size")
plt.ylabel("Emission")
plt.show()

## Plot the relation between cylinders vs co2 emission

plt.scatter(cdf.CYLINDERS, cdf.CO2EMISSIONS,  color='blue')
plt.xlabel("Cylinder")
plt.ylabel("Emission")
plt.show()


## Train/Test Split:
## splitting the dataset into training and testing sets respectively, which are mutually exclusive. 
## You train with the training set and test with the testing set. 
## This will provide a more accurate evaluation on out-of-sample accuracy because the testing dataset is not part of the dataset that have been used to train the data.


## Split our dataset into train and test sets, 80% of the entire data for training, and the 20% for testing. 
## Create a mask to select random rows using np.random.rand() function:

msk = np.random.rand(len(df)) < 0.8
train = cdf[msk]
test = cdf[~msk]

## Simple linear regression
## Linear Regression fits a linear model with coefficients $\theta = (\theta_1, ..., \theta_n)$ 
## to minimize the 'residual sum of squares' between the independent x in the dataset, and the dependent y by the linear approximation. 


plt.scatter(train.ENGINESIZE, train.CO2EMISSIONS,  color='blue')
plt.xlabel("Engine size")
plt.ylabel("Emission")
plt.show()

## This graph seems to have an 'optimal line' that fits the data y = \theta_0 + \theta_1 x

## How to calculate \theta_0 and \theta_1
from sklearn import linear_model
regr = linear_model.LinearRegression()
train_x = np.asanyarray(train[['ENGINESIZE']])
train_y = np.asanyarray(train[['CO2EMISSIONS']])
regr.fit (train_x, train_y)


## The coefficients: Coefficient and Intercept in the simple linear regression, are the parameters of the fit line. 
print ('Coefficients: ', regr.coef_) 
print ('Intercept: ',regr.intercept_)

## Plot the lne and the scatter graph
plt.scatter(train.ENGINESIZE, train.CO2EMISSIONS,  color='blue')
plt.plot(train_x, regr.coef_[0][0]*train_x + regr.intercept_[0], '-r')
plt.xlabel("Engine size")
plt.ylabel("Emission")


## Accuracy of the test

from sklearn.metrics import r2_score

test_x = np.asanyarray(test[['ENGINESIZE']])
test_y = np.asanyarray(test[['CO2EMISSIONS']])
test_y_hat = regr.predict(test_x)

print("Mean absolute error: %.2f" % np.mean(np.absolute(test_y_hat - test_y)))
print("Residual sum of squares (MSE): %.2f" % np.mean((test_y_hat - test_y) ** 2))
print("R2-score: %.2f" % r2_score(test_y_hat , test_y) )
